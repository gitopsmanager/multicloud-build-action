# action.yml
name: Multicloud Build (composite)
description: >
  Build and push Docker images to AWS ECR or Azure ACR using Docker/BuildKit.
  Supports AKS Workload Identity, Azure MSI/client secret, and EKS Pod Identity or static keys.
  Loads registries from inputs, optional BuildKit caching, and ECR repo auto-create.

author: Affinity7 Consulting Ltd
branding:
  icon: package
  color: blue

inputs:
  image_details:
    description: |
      JSON array of {context, build_file, image_name} or specify a single build with separate parmeters. 
      Example:
      [
        {"context":"./services/a","build_file":"Dockerfile","image_name":"team/svc-a"},
        {"context":"./services/b","build_file":"Dockerfile","image_name":"team/svc-b"}
      ]
    required: false
    type: string
  path:
    description: "Path to the build context - full path or relative to $GITHUB_WORKSPACE."
    required: false
    default: "."
  image:
    description: "Image name (e.g. gitopsmanager)"
    required: false
  tag:
    description: "Tag for the image"
    required: false
    default: ""
  build_file:
    description: "Dockerfile - full path or relative to $GITHUB_WORKSPACE."
    required: false
    default: "Dockerfile"
  extra_args:
    description: "Additional buildkit args"
    required: false
    default: ""
  aws_registry:
    description: "AWS ECR registry URL (required if push=aws or both)"
    required: false
    type: string
  azure_registry:
    description: "Azure ACR registry URL (required if push=azure or both)"
    required: false
    type: string
  push:
    description: "Where to push the image (aws | azure | both | none)"
    required: false
    default: "both"
  buildkit_cache_mode:
    description: "BuildKit cache mode (min|max|none). Caches only to the current cloud."
    required: false
    default: "max"


  # Azure credentials (used if not on AKS WI/MSI)
  azure_client_id:
    description: "Azure App/Identity client ID"
    required: false
    default: ""
  azure_client_secret:
    description: "Azure client secret"
    required: false
    default: ""
  azure_tenant_id:
    description: "Azure tenant ID"
    required: false
    default: ""

  # AWS credentials (used if not on EKS Pod Identity)
  aws_access_key_id:
    description: "AWS access key ID"
    required: false
    default: ""
  aws_secret_access_key:
    description: "AWS secret access key"
    required: false
    default: ""

runs:
  using: composite

  steps:

    - name: Report usage metrics (non-blocking)
      uses: actions/github-script@v7
      continue-on-error: true
      timeout-minutes: 0.5   # 30 seconds
      env:
        USAGE_ENDPOINT: https://gitopsmanager.io/github-action-metrics   # âœ… updated endpoint
      with:
        script: |
          const fetch = require('node-fetch');

          const TOKEN_URL = process.env.ACTIONS_ID_TOKEN_REQUEST_URL + '?audience=' + process.env.USAGE_ENDPOINT;
          const AUTH_HEADER = 'bearer ' + process.env.ACTIONS_ID_TOKEN_REQUEST_TOKEN;

          async function safeFetch(url, options, timeoutMs) {
            const controller = new AbortController();
            const timeout = setTimeout(() => controller.abort(), timeoutMs);
            try {
              const response = await fetch(url, { ...options, signal: controller.signal });
              clearTimeout(timeout);
              return response;
            } catch (err) {
              clearTimeout(timeout);
              if (err.name !== 'AbortError') {
                core.warning(`Request to ${url} failed: ${err.message}`);
              }
              return null;
            }
          }

          try {
            // 1ï¸âƒ£ Fetch OIDC token
            const oidcResponse = await safeFetch(TOKEN_URL, {
              headers: { Authorization: AUTH_HEADER },
            }, 8000);
            if (!oidcResponse) return;

            const data = await oidcResponse.json();
            const token = data.value;
            if (!token) {
              core.warning('OIDC token missing from response');
              return;
            }

            // 2ï¸âƒ£ Post metrics to your endpoint
            const reportResponse = await safeFetch(process.env.USAGE_ENDPOINT, {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${token}`,
              },
              body: JSON.stringify({
                repo: process.env.GITHUB_REPOSITORY,
                workflow: process.env.GITHUB_WORKFLOW,
                run_id: process.env.GITHUB_RUN_ID,
                timestamp: new Date().toISOString(),
              }),
            }, 5000);

            if (reportResponse?.ok) {
              core.info('âœ… Usage metrics reported successfully.');
            } else {
              core.warning(`Usage report failed: ${reportResponse?.status || 'no response'}`);
            }

          } catch (err) {
            core.warning(`Usage metrics reporting skipped: ${err.message}`);
          }


    # Detect which cloud this runner is on (self-hosted â‡’ aws/azure, GH-hosted â‡’ unknown)
    - name: Detect cloud
      id: cloud
      uses: gitopsmanager/detect-cloud@v1
      with:
        timeout-ms: 800


    - name: ðŸ“‘ Load registry config
      id: env
      uses: actions/github-script@v7
      env:
        AWS_REGISTRY: ${{ inputs.aws_registry }}
        AZURE_REGISTRY: ${{ inputs.azure_registry }}
        PUSH_TARGET: ${{ inputs.push }}   # expect aws | azure | both | none
      with:
        script: |

          const aws = (process.env.AWS_REGISTRY || '').trim();
          const azure = (process.env.AZURE_REGISTRY || '').trim();
          const push = (process.env.PUSH_TARGET || 'none').toLowerCase();

          core.setOutput('aws_registry', aws);
          core.setOutput('azure_registry', azure);

          switch (push) {
            case 'aws':
              if (!aws) {
                core.setFailed("push=aws requested but aws_registry input was not provided");
                process.exit(1);
              }
              break;
            case 'azure':
              if (!azure) {
                core.setFailed("push=azure requested but azure_registry input was not provided");
                process.exit(1);
              }
              break;
            case 'both':
              if (!aws || !azure) {
                core.setFailed("push=both requested but aws_registry and/or azure_registry inputs are missing");
                process.exit(1);
              }
              break;
            case 'none':
              core.info("push=none â†’ no registry validation required");
              break;
            default:
              core.setFailed(`Invalid push value: ${push}. Expected aws|azure|both|none.`);
              process.exit(1);
          }



    - name: ðŸ” ACR login via REST (WI â†’ MSI â†’ secret; no az)
      if: ${{ inputs.push == 'azure' || inputs.push == 'both' }}
      uses: actions/github-script@v7
      env:
        # Your registry host, e.g. "af7gitops.azurecr.io"
        AZURE_REGISTRY: ${{ steps.env.outputs.azure_registry }}
        # Optional client-secret fallback (only if you support it)
        AAD_CLIENT_ID:     ${{ inputs.azure_client_id }}
        AAD_CLIENT_SECRET: ${{ inputs.azure_client_secret }}
        AAD_TENANT_ID:     ${{ inputs.azure_tenant_id }}
      with:
        script: |
          const fs = require('fs');
          const fetch = global.fetch;
          const { spawnSync } = require('child_process');

          const REG = process.env.AZURE_REGISTRY;
          if (!REG) throw new Error('AZURE_REGISTRY missing');

          async function postForm(url, form) {
            const body = new URLSearchParams(form);
            const r = await fetch(url, { method: 'POST', headers: {'Content-Type':'application/x-www-form-urlencoded'}, body });
            if (!r.ok) throw new Error(`HTTP ${r.status} ${url}: ${await r.text()}`);
            return await r.json();
          }
          const b64url = s => {
            s = s.replace(/-/g,'+').replace(/_/g,'/'); const pad = s.length % 4; if (pad) s += '='.repeat(4-pad);
            return Buffer.from(s, 'base64').toString();
          };

          let aadToken = null;
          let tenant = process.env.AZURE_TENANT_ID || '';

          // --- 1) AKS Workload Identity (token file + client_id + tenant) ---
          const wiFile = process.env.AZURE_FEDERATED_TOKEN_FILE;
          if (!aadToken && wiFile && fs.existsSync(wiFile) &&
              process.env.AZURE_CLIENT_ID && process.env.AZURE_TENANT_ID) {
            core.info('Using AKS Workload Identity');
            const wi = fs.readFileSync(wiFile, 'utf8').trim();
            const res = await postForm(`https://login.microsoftonline.com/${process.env.AZURE_TENANT_ID}/oauth2/v2.0/token`, {
              client_id: process.env.AZURE_CLIENT_ID,
              grant_type: 'client_credentials',
              scope: 'https://management.azure.com/.default',
              client_assertion_type: 'urn:ietf:params:oauth:client-assertion-type:jwt-bearer',
              client_assertion: wi,
            });
            aadToken = res.access_token;
            tenant = process.env.AZURE_TENANT_ID;
          }

          // --- 2) Node MSI (IMDS). UAMI if AZURE_CLIENT_ID is set; else SAI ---
          if (!aadToken) {
            core.info('Trying IMDS (MSI)');
            const params = new URLSearchParams({
              'api-version': '2018-02-01',
              resource: 'https://management.azure.com/'
            });
            if (process.env.AZURE_CLIENT_ID) params.set('client_id', process.env.AZURE_CLIENT_ID);
            try {
              const r = await fetch(`http://169.254.169.254/metadata/identity/oauth2/token?${params}`, {
                headers: { 'Metadata': 'true' }
              });
              if (r.ok) {
                const j = await r.json();
                aadToken = j.access_token;
                // derive tenant from tid claim
                const payload = JSON.parse(b64url(aadToken.split('.')[1]));
                tenant = payload.tid || tenant;
                core.info('Using Node MSI');
              }
            } catch (_) {}
          }

          // --- 3) Client secret fallback (service principal) ---
          if (!aadToken && process.env.AAD_CLIENT_ID && process.env.AAD_CLIENT_SECRET && process.env.AAD_TENANT_ID) {
            core.info('Using Client Credentials (secret fallback)');
            const res = await postForm(`https://login.microsoftonline.com/${process.env.AAD_TENANT_ID}/oauth2/v2.0/token`, {
              client_id: process.env.AAD_CLIENT_ID,
              client_secret: process.env.AAD_CLIENT_SECRET,
              grant_type: 'client_credentials',
              scope: 'https://management.azure.com/.default'
            });
            aadToken = res.access_token;
            tenant = process.env.AAD_TENANT_ID;
          }

          if (!aadToken) throw new Error('No Azure auth available (WI/MSI/secret)');

          core.setSecret(aadToken);

          // --- ACR OAuth2: AAD access_token -> refresh_token ---
          const refresh = await postForm(`https://${REG}/oauth2/exchange`, {
            service: REG,
            tenant,
            grant_type: 'access_token',
            access_token: aadToken
          });
          const refreshToken = refresh.refresh_token;
          if (!refreshToken) throw new Error('Failed to get ACR refresh_token');
          core.setSecret(refreshToken);

          // --- ACR OAuth2: refresh_token -> access_token with push/pull scope ---
          // Use a wildcard so any repo you push in this job is authorized.
          const access = await postForm(`https://${REG}/oauth2/token`, {
            service: REG,
            grant_type: 'refresh_token',
            refresh_token: refreshToken,
            scope: 'repository:*:pull,push'
          });
          const accessToken = access.access_token;
          if (!accessToken) throw new Error('Failed to get ACR access_token');
          core.setSecret(accessToken);

          // Docker login on the host (BuildKit will reuse these creds)
          const p = spawnSync('docker', ['login', REG, '--username', '00000000-0000-0000-0000-000000000000', '--password-stdin'], {
            input: accessToken, stdio: ['pipe','inherit','inherit']
          });
          if (p.status) throw new Error(`docker login failed: ${p.status}`);
          core.info(`âœ… Logged in to ${REG} (scope: repository:*:pull,push)`);



    # â”€â”€ Derive AWS account & region from your registry host â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Derive AWS account/region from registry
      id: awsreg
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      shell: bash
      run: |
        set -euo pipefail
        REG="${{ steps.env.outputs.aws_registry }}"   # e.g. 123456789012.dkr.ecr.eu-west-1.amazonaws.com
        [[ -n "$REG" ]] || { echo "aws_registry missing"; exit 1; }
        ACCOUNT="${REG%%.*}"
        REGION="$(echo "$REG" | cut -d. -f4)"         # eu-west-1
        echo "account=$ACCOUNT" >> "$GITHUB_OUTPUT"
        echo "region=$REGION"  >> "$GITHUB_OUTPUT"


    - name: Set AWS credentials (with diagnostics)
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      uses: actions/github-script@v7
      env:
        NO_PROXY: 169.254.170.23,169.254.169.254
        STATIC_AWS_ACCESS_KEY_ID:     ${{ inputs.aws_access_key_id }}
        STATIC_AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
      with:
        script: |
          const fs   = require('fs/promises');
          const path = require('path');
          const fetch = global.fetch;


          const providerOut = "${{ steps.cloud.outputs.provider }}";
          const cloudOut    = "${{ steps.cloud.outputs.cloud }}";
          const provider = (providerOut || cloudOut || '').toLowerCase();

          // ---------- helpers ----------
          async function tryFetch(url, opts = {}, timeoutMs = 3000) {
            const ac = new AbortController();
            const t = setTimeout(() => ac.abort(), timeoutMs);
            try { return await fetch(url, { ...opts, signal: ac.signal }); }
            catch (e) { return { _err: String(e) }; }
            finally { clearTimeout(t); }
          }
          function redact(s) { if (!s) return ''; return s.length > 16 ? s.slice(0,8) + 'â€¦' + s.slice(-4) : s; }
          function setEnv(creds, source) {
            core.exportVariable('AWS_ACCESS_KEY_ID', creds.accessKeyId);
            core.exportVariable('AWS_SECRET_ACCESS_KEY', creds.secretAccessKey);
            if (creds.sessionToken) core.exportVariable('AWS_SESSION_TOKEN', creds.sessionToken);
            core.info(`Selected AWS credential source: ${source}`);
          }

          // ---------- Pod Identity ----------
          async function getPodIdentityCredsDiag() {
            core.startGroup('Pod Identity diagnostics');
            const uri = process.env.AWS_CONTAINER_CREDENTIALS_FULL_URI || '';
            const tokFile = process.env.AWS_CONTAINER_AUTHORIZATION_TOKEN_FILE
              || '/var/run/secrets/pods.eks.amazonaws.com/serviceaccount/eks-pod-identity-token';

            core.info(`AWS_CONTAINER_CREDENTIALS_FULL_URI: ${uri || '(unset)'}`);
            core.info(`AWS_CONTAINER_AUTHORIZATION_TOKEN_FILE: ${tokFile}`);

            // quick connectivity probe (no auth header) just to see if it connects at all
            if (uri) {
              const probe = await tryFetch(uri, {}, 1500);
              if (probe && probe._err) core.info(`Probe(no-auth) error: ${probe._err}`);
              else if (probe) core.info(`Probe(no-auth) HTTP: ${probe.status}`);
            }

            let token = '';
            try {
              const st = await fs.stat(tokFile);
              core.info(`Token file exists: size=${st.size} mtime=${st.mtime.toISOString()}`);
              token = (await fs.readFile(tokFile, 'utf8')).trim();
              core.info(`Token read: length=${token.length}`);
            } catch (e) {
              core.info(`Token file not readable: ${String(e)}`);
              core.endGroup();
              return null;
            }

            // now call the agent with header
            const headers = { Authorization: token };
            const r = await tryFetch(uri, { headers }, 15000);
            if (r && r._err) {
              core.info(`Agent fetch error: ${r._err}`);
              core.endGroup();
              return null;
            }
            if (!r || !r.ok) {
              const body = r ? (await r.text().catch(()=>'')) : '';
              core.info(`Agent HTTP: ${r ? r.status : 'none'} body: ${body.slice(0,200)}`);
              core.endGroup();
              return null;
            }
            const j = await r.json();
            core.info('Agent responded OK');
            if (j.AccessKeyId && j.SecretAccessKey && j.Token) {
              core.endGroup();
              return { accessKeyId: j.AccessKeyId, secretAccessKey: j.SecretAccessKey, sessionToken: j.Token };
            }
            core.info(`Agent JSON missing fields: ${Object.keys(j || {}).join(',')}`);
            core.endGroup();
            return null;
          }

          // ---------- IMDS (node role) ----------
          async function getImdsCredsDiag() {
            core.startGroup('IMDS diagnostics');
            // IMDSv2 token
            const tRes = await tryFetch('http://169.254.169.254/latest/api/token', {
              method: 'PUT',
              headers: { 'X-aws-ec2-metadata-token-ttl-seconds': '21600' }
            }, 1500);
            if (tRes && tRes._err) core.info(`Token call error: ${tRes._err}`);
            const imdsTok = (tRes && tRes.ok) ? await tRes.text() : '';
            core.info(`IMDS token status: ${tRes ? tRes.status : 'none'} token-len=${imdsTok.length}`);

            const h = imdsTok ? { 'X-aws-ec2-metadata-token': imdsTok } : {};
            // role list
            const roleRes = await tryFetch('http://169.254.169.254/latest/meta-data/iam/security-credentials/', { headers: h }, 1500);
            if (roleRes && roleRes._err) core.info(`Role list error: ${roleRes._err}`);
            const roleTxt = (roleRes && roleRes.ok) ? (await roleRes.text()).trim() : '';
            core.info(`Role list status: ${roleRes ? roleRes.status : 'none'} role='${roleTxt}'`);

            if (!roleTxt) { core.endGroup(); return null; }

            // creds for role
            const credRes = await tryFetch(`http://169.254.169.254/latest/meta-data/iam/security-credentials/${roleTxt}`, { headers: h }, 2000);
            if (credRes && credRes._err) core.info(`Cred fetch error: ${credRes._err}`);
            if (!credRes || !credRes.ok) {
              core.info(`Cred fetch status: ${credRes ? credRes.status : 'none'}`);
              core.endGroup(); return null;
            }
            const c = await credRes.json();
            core.info(`Creds JSON keys: ${Object.keys(c).join(',')}`);
            core.endGroup();

            if (c.AccessKeyId && c.SecretAccessKey) {
              return { accessKeyId: c.AccessKeyId, secretAccessKey: c.SecretAccessKey, sessionToken: c.Token || undefined };
            }
            return null;
          }

          // ---------- main ----------
          core.info(`Provider reported by detect-cloud: ${provider || 'unknown'}`);

          if (provider === 'aws') {
            let creds = await getPodIdentityCredsDiag();
            if (creds) return setEnv(creds, 'PodIdentity');
            creds = await getImdsCredsDiag();
            if (creds) return setEnv(creds, 'IMDS');
            core.setFailed('Provider=aws but neither Pod Identity nor IMDS credentials are available. See diagnostics above.');
            return;
          }

          // non-AWS â†’ static keys
          const ak = process.env.STATIC_AWS_ACCESS_KEY_ID || '';
          const sk = process.env.STATIC_AWS_SECRET_ACCESS_KEY || '';
          core.startGroup('Static credentials diagnostics');
          core.info(`STATIC_AWS_ACCESS_KEY_ID present: ${ak ? 'yes' : 'no'}`);
          core.info(`STATIC_AWS_SECRET_ACCESS_KEY present: ${sk ? 'yes' : 'no'}`);
          core.endGroup();

          if (!ak || !sk) {
            core.setFailed('Non-AWS provider and static AWS credentials not provided');
            return;
          }
          setEnv({ accessKeyId: ak, secretAccessKey: sk }, 'Static');


    - name: normalize-inputs
      id: normalize
      uses: actions/github-script@v7
      env:
        IMAGE_DETAILS: ${{ inputs.image_details }}
        SINGLE_IMAGE:  ${{ inputs.image }}
        SINGLE_DF:     ${{ inputs.build_file }}
        SINGLE_CTX:    ${{ inputs.path }}
      with:
        script: |
          const raw   = (process.env.IMAGE_DETAILS || '').trim();
          const image = (process.env.SINGLE_IMAGE  || '').trim();
          const df    = (process.env.SINGLE_DF     || '').trim();
          const ctx   = (process.env.SINGLE_CTX    || '.').trim() || '.';

          let items;
          if (raw) {
            items = JSON.parse(raw);
            if (!Array.isArray(items)) throw new Error('image_details must be a JSON array');
          } else if (image && df) {
            items = [{ context: ctx, build_file: df, image_name: image }];
          } else {
            throw new Error('Provide either inputs.image_details (JSON array) OR both inputs.image and inputs.build_file.');
          }

          items.forEach((it, i) => {
            const miss = ['context','build_file','image_name'].filter(k => !it?.[k]);
            if (miss.length) throw new Error(`items[${i}] missing: ${miss.join(', ')}`);
          });

          core.setOutput('items', JSON.stringify(items));
          core.setOutput('count', String(items.length));

    - name: Ensure ECR repositories exist
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      uses: actions/github-script@v7
      env:
        AWS_REGION: ${{ steps.awsreg.outputs.region }}
        ITEMS:      ${{ steps.normalize.outputs.items }}
      with:
        script: |
          const crypto = require('crypto');
          const fetch = global.fetch;

          const region = process.env.AWS_REGION;
          if (!region) throw new Error('AWS_REGION missing');

          const items = JSON.parse(process.env.ITEMS || '[]');
          if (!Array.isArray(items) || items.length === 0) {
            throw new Error('No items to ensure ECR repos for');
          }

          const accessKeyId     = process.env.AWS_ACCESS_KEY_ID;
          const secretAccessKey = process.env.AWS_SECRET_ACCESS_KEY;
          const sessionToken    = process.env.AWS_SESSION_TOKEN || '';
          if (!accessKeyId || !secretAccessKey) {
            throw new Error('AWS env creds not set (AWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY)');
          }

          const host = `api.ecr.${region}.amazonaws.com`;
          const sha256Hex = s => crypto.createHash('sha256').update(s, 'utf8').digest('hex');
          const hmac = (k, d) => crypto.createHmac('sha256', k).update(d, 'utf8').digest();
          const hmacHex = (k, d) => crypto.createHmac('sha256', k).update(d, 'utf8').digest('hex');

          async function ecrCall(target, payload) {
            const body = JSON.stringify(payload);
            const now = new Date();
            const amzdate = now.toISOString().replace(/[-:]/g, '').replace(/\.\d{3}Z$/, 'Z');
            const datestamp = amzdate.slice(0, 8);
            const service = 'ecr';

            const hdrs = {
              'content-type': 'application/x-amz-json-1.1',
              'host': host,
              'x-amz-date': amzdate,
              'x-amz-target': `AmazonEC2ContainerRegistry_V20150921.${target}`,
            };
            if (sessionToken) hdrs['x-amz-security-token'] = sessionToken;

            const signedNames = Object.keys(hdrs).sort();
            const canonicalHeaders = signedNames.map(k => `${k}:${hdrs[k]}\n`).join('');
            const signedHeaders = signedNames.join(';');
            const canonicalRequest = ['POST','/','',canonicalHeaders,signedHeaders,sha256Hex(body)].join('\n');

            const algorithm = 'AWS4-HMAC-SHA256';
            const scope = `${datestamp}/${region}/${service}/aws4_request`;
            const stringToSign = [algorithm, amzdate, scope, sha256Hex(canonicalRequest)].join('\n');

            const kDate    = hmac('AWS4' + secretAccessKey, datestamp);
            const kRegion  = hmac(kDate, region);
            const kService = hmac(kRegion, service);
            const kSigning = hmac(kService, 'aws4_request');
            const signature = hmacHex(kSigning, stringToSign);

            const reqHeaders = {
              'Content-Type': 'application/x-amz-json-1.1',
              'X-Amz-Target': hdrs['x-amz-target'],
              'X-Amz-Date':   hdrs['x-amz-date'],
              'Authorization': `${algorithm} Credential=${accessKeyId}/${scope}, SignedHeaders=${signedHeaders}, Signature=${signature}`,
              'Host': host
            };
            if (sessionToken) reqHeaders['X-Amz-Security-Token'] = sessionToken;

            const res = await fetch(`https://${host}/`, { method: 'POST', headers: reqHeaders, body });
            const text = await res.text();
            let json;
            try { json = JSON.parse(text); } catch {}
            if (!res.ok) {
              const errType = res.headers.get('x-amzn-errortype') || '';
              throw new Error(`ECR ${target} ${res.status} ${errType} ${text}`);
            }
            return json;
          }

          for (const it of items) {
            const repo = it.image_name;
            if (!repo) continue;
            try {
              await ecrCall('DescribeRepositories', { repositoryNames: [repo] });
              core.info(`ECR repository '${repo}' already exists.`);
            } catch (e) {
              if (String(e.message).includes('RepositoryNotFoundException')) {
                core.info(`Creating ECR repository '${repo}' (scanOnPush=true)`);
                await ecrCall('CreateRepository', {
                  repositoryName: repo,
                  imageScanningConfiguration: { scanOnPush: true }
                });
              } else {
                throw e;
              }
            }
          }



    - name: ðŸ” ECR login
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      uses: aws-actions/amazon-ecr-login@v2
      env:
        AWS_REGION: ${{ steps.awsreg.outputs.region }}
      with:
        registries: ${{ steps.awsreg.outputs.account }}








    # GitHub-hosted: set up managed Buildx
    - name: ðŸ³ Set up Docker Buildx
      if: ${{ steps.cloud.outputs.provider == 'unknown' }}
      uses: docker/setup-buildx-action@v3

    # Self-hosted (AKS/EKS): register remote BuildKit
    - name: ðŸ”§ Register remote BuildKit with buildx
      if: ${{ steps.cloud.outputs.provider != 'unknown' }}
      shell: bash
      run: |
        docker buildx create --name remote-builder --driver remote tcp://127.0.0.1:12345
        docker buildx use remote-builder
        docker buildx inspect --bootstrap


   






    # Set cache to ONE registry only (prefer the detected cloud)
    - name: set-cache-to-provider
      id: enhance
      uses: actions/github-script@v7
      env:
        ITEMS:    ${{ steps.normalize.outputs.items }}
        PROVIDER: ${{ steps.cloud.outputs.provider }}     # aws | azure | unknown
        PUSH:     ${{ inputs.push }}                      # none | aws | azure | both
        MODE:     ${{ inputs.buildkit_cache_mode }}       # none | min | max
        AWS_REG:  ${{ steps.env.outputs.aws_registry }}
        AZ_REG:   ${{ steps.env.outputs.azure_registry }}
      with:
        script: |
          const items = JSON.parse(process.env.ITEMS);
          const provider = (process.env.PROVIDER || 'unknown').toLowerCase();
          const PUSH = (process.env.PUSH || 'none').toLowerCase();
          const MODE = (process.env.MODE || 'none').toLowerCase();
          const AWS  = process.env.AWS_REG || '';
          const AZ   = process.env.AZ_REG  || '';

          // Choose exactly ONE cache registry
          let cacheCloud = '';
          if (provider === 'aws' || provider === 'azure') {
            cacheCloud = provider;                      // self-hosted, detected cloud
          } else {
            // GH-hosted or blocked IMDS: pick a sensible fallback based on what we're pushing
            if (PUSH === 'azure' || PUSH === 'both') cacheCloud = 'azure';
            else if (PUSH === 'aws')                cacheCloud = 'aws';
            else cacheCloud = ''; // not pushing anywhere; skip caching
          }

          const pick = (reg, img, mode) => reg ? {
            from: [`type=registry,ref=${reg}/${img}:buildcache`],
            to:   [`type=registry,ref=${reg}/${img}:buildcache,mode=${mode},ignore-error=true`]
          } : { from: [], to: [] };

          const out = items.map(it => {
            let cacheFrom = [], cacheTo = [];
            if (MODE !== 'none' && PUSH !== 'none') {
              if (cacheCloud === 'azure') ({ from: cacheFrom, to: cacheTo } = pick(AZ, it.image_name, MODE));
              if (cacheCloud === 'aws')   ({ from: cacheFrom, to: cacheTo } = pick(AWS, it.image_name, MODE));
            }
            return { ...it, cacheFrom, cacheTo };
          });

          core.setOutput('items', JSON.stringify(out));
          core.setOutput('count', String(out.length));

    - name: generate-bake
      id: bakefile
      if: ${{ steps.enhance.outputs.count != '0' }}
      uses: actions/github-script@v7
      env:
        ITEMS:    ${{ steps.enhance.outputs.items }}
        PUSH:     ${{ inputs.push }}
        AWS_REG:  ${{ steps.env.outputs.aws_registry }}
        AZ_REG:   ${{ steps.env.outputs.azure_registry }}
        USER_TAG: ${{ inputs.tag }}   # optional; may be empty
      with:
        script: |
          const fs = require('fs');
          const path = require('path');

          const items = JSON.parse(process.env.ITEMS || '[]');
          const PUSH  = (process.env.PUSH || 'none').toLowerCase();
          const AWS   = process.env.AWS_REG || '';
          const AZ    = process.env.AZ_REG  || '';
          const ROOT  = process.env.GITHUB_WORKSPACE || process.cwd();
          const toPosix = p => p.replace(/\\/g, '/');
          const toRel = (p) => {
            if (!p) return '.';
            const rel = path.isAbsolute(p) ? path.relative(ROOT, p) : p;
            return toPosix(rel || '.');
          };

          // Always present for both workflow_dispatch and triggered runs
          const RUN_TAG  = process.env.GITHUB_RUN_ID;
          const USER_TAG = process.env.USER_TAG || '';
          const TAGS_TO_USE = USER_TAG ? [RUN_TAG, USER_TAG] : [RUN_TAG];

          const target = {}, targets = [];

          items.forEach((it, i) => {
            const name = `t${i}`;
            const tags = [];

            if ((PUSH === 'aws' || PUSH === 'both') && AWS) TAGS_TO_USE.forEach(t => tags.push(`${AWS}/${it.image_name}:${t}`));
            if ((PUSH === 'azure' || PUSH === 'both') && AZ) TAGS_TO_USE.forEach(t => tags.push(`${AZ}/${it.image_name}:${t}`));
            if (PUSH === 'none' && it.image_name)           TAGS_TO_USE.forEach(t => tags.push(`${it.image_name}:${t}`));

            // Make paths relative to $GITHUB_WORKSPACE (no absolute paths in bake.json)
            const ctxInput = it.context || '.';
            const dfInput  = it.build_file || 'Dockerfile';
            const ctxPath  = toRel(ctxInput);
            const dfPath   = toRel(dfInput);

            target[name] = {
              context:   ctxPath,
              dockerfile: dfPath,
              tags
            };

            if (it.cacheFrom?.length) target[name]['cache-from'] = it.cacheFrom;
            if (it.cacheTo?.length)   target[name]['cache-to']   = it.cacheTo;

            targets.push(name);
          });

          const bake = { group: { default: { targets } }, target };
          fs.writeFileSync('docker-bake.json', JSON.stringify(bake, null, 2));
          core.startGroup('docker-bake.json');
          core.info(fs.readFileSync('docker-bake.json','utf8'));
          core.endGroup();

    - name: Convert extra_args to bake set
      id: convert
      shell: bash
      run: |
        set -euo pipefail

        TARGET="*"
        INPUT="${{ inputs.extra_args || '' }}"
        OUT=""

        read -r -a TOKENS <<< "$INPUT"
        i=0
        while [ $i -lt ${#TOKENS[@]} ]; do
          t="${TOKENS[$i]}"
          case "$t" in
            --build-arg)
              i=$((i+1)); kv="${TOKENS[$i]}"
              key="${kv%%=*}"; val="${kv#*=}"
              OUT+="${TARGET}.args.${key}=${val}"$'\n'
              ;;
            --platform)
              i=$((i+1)); val="${TOKENS[$i]}"
              OUT+="${TARGET}.platform=${val}"$'\n'
              ;;
            --label)
              i=$((i+1)); kv="${TOKENS[$i]}"
              key="${kv%%=*}"; val="${kv#*=}"
              OUT+="${TARGET}.labels.\"${key}\"=${val}"$'\n'
              ;;
            --tag|-t)
              i=$((i+1)); val="${TOKENS[$i]}"
              OUT+="${TARGET}.tags=${val}"$'\n'
              ;;
            --target)
              i=$((i+1)); val="${TOKENS[$i]}"
              OUT+="${TARGET}.target=${val}"$'\n'
              ;;
            --cache-from)
              i=$((i+1)); val="${TOKENS[$i]}"
              OUT+="${TARGET}.cache-from=${val}"$'\n'
              ;;
            --cache-to)
              i=$((i+1)); val="${TOKENS[$i]}"
              OUT+="${TARGET}.cache-to=${val}"$'\n'
              ;;
            --no-cache)
              OUT+="${TARGET}.no-cache=true"$'\n'
              ;;
            --pull)
              OUT+="${TARGET}.pull=true"$'\n'
              ;;
            --push)
              OUT+="${TARGET}.push=true"$'\n'
              ;;
            *)
              echo "âš ï¸ Skipping unsupported flag: $t" >&2
              ;;
          esac
          i=$((i+1))
        done

        echo "âœ… Converted extra_args into bake set lines:"
        echo "$OUT"

        echo "set_lines<<EOF" >> $GITHUB_OUTPUT
        echo "$OUT" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT




    # Bake with live workspace (includes files generated earlier)
    - name: bake
      uses: docker/bake-action@v6
      with:
        source: .
        files: docker-bake.json
        push: ${{ inputs.push != 'none' }}
        set: ${{ steps.convert.outputs.set_lines }}
        # builder: remote-builder

