# action.yml
name: Multicloud Build (composite)
description: >
  Build and push Docker images to AWS ECR or Azure ACR using Docker/BuildKit.
  Supports AKS Workload Identity, Azure MSI/client secret, and EKS Pod Identity or static keys.
  Loads default registries from a CD repo, optional BuildKit caching, and ECR repo auto-create.

author: Affinity7 Consulting Ltd
branding:
  icon: package
  color: blue

inputs:
  image_details:
    description: |
      JSON array of {context, build_file, image_name} or specify a single build with separate parmeters. 
      Example:
      [
        {"context":"./services/a","build_file":"Dockerfile","image_name":"team/svc-a"},
        {"context":"./services/b","build_file":"Dockerfile","image_name":"team/svc-b"}
      ]
    required: false
    type: string
  path:
    description: "Path to the build context - full path or relative to $GITHUB_WORKSPACE."
    required: false
    default: "."
  image:
    description: "Image name (e.g. gitopsmanager)"
    required: true
  tag:
    description: "Tag for the image"
    required: false
    default: ""
  build_file:
    description: "Dockerfile - full path or relative to $GITHUB_WORKSPACE."
    required: false
    default: "Dockerfile"
  extra_args:
    description: "Additional buildkit args"
    required: false
    default: ""

  cd_repo:
    description: "CD repo (owner/repo) with cd/config/env-map.yaml providing default registries"
    required: true

  push:
    description: "Where to push the image (aws | azure | both | none)"
    required: false
    default: "none"

  buildkit_cache_mode:
    description: "BuildKit cache mode (min|max|none). Caches only to the current cloud."
    required: false
    default: "max"

  # GitHub App for CD repo checkout
  cd_app_id:
    description: "GitHub App ID for CD repo access"
    required: true
  cd_app_private_key:
    description: "GitHub App private key (PEM) for CD repo access"
    required: true

  # Azure credentials (used if not on AKS WI/MSI)
  azure_client_id:
    description: "Azure App/Identity client ID"
    required: false
    default: ""
  azure_client_secret:
    description: "Azure client secret"
    required: false
    default: ""
  azure_tenant_id:
    description: "Azure tenant ID"
    required: false
    default: ""

  # AWS credentials (used if not on EKS Pod Identity)
  aws_access_key_id:
    description: "AWS access key ID"
    required: false
    default: ""
  aws_secret_access_key:
    description: "AWS secret access key"
    required: false
    default: ""

runs:
  using: composite

  steps:

    - name: 🔑 Generate GitHub App token
      id: generate_token
      uses: tibdex/github-app-token@v2.1.0
      with:
        app_id: ${{ inputs.cd_app_id }}
        private_key: ${{ inputs.cd_app_private_key }}
        installation_retrieval_mode: repository
        installation_retrieval_payload: ${{ inputs.cd_repo }}
        revoke: true



    - name: 📂 Checkout CD repo
      uses: actions/checkout@v4
      with:
        repository: ${{ inputs.cd_repo }}
        token: ${{ steps.generate_token.outputs.token }}
        path: cd

    - name: 📑 Load environment config
      id: env
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');

          const cfg = JSON.parse(
            fs.readFileSync(path.join(process.env.GITHUB_WORKSPACE, 'cd/config/env-map.json'), 'utf8')
          );
          core.setOutput('aws_registry',   cfg.build.aws_default_container_registry);
          core.setOutput('azure_registry', cfg.build.azure_default_container_registry);

    - name: 🔐 ACR login via REST (WI → MSI → secret; no az)
      if: ${{ inputs.push == 'azure' || inputs.push == 'both' }}
      uses: actions/github-script@v7
      env:
        # Your registry host, e.g. "af7gitops.azurecr.io"
        AZURE_REGISTRY: ${{ steps.env.outputs.azure_registry }}
        # Optional client-secret fallback (only if you support it)
        AAD_CLIENT_ID:     ${{ inputs.azure_client_id }}
        AAD_CLIENT_SECRET: ${{ inputs.azure_client_secret }}
        AAD_TENANT_ID:     ${{ inputs.azure_tenant_id }}
      with:
        script: |
          const fs = require('fs');
          const fetch = global.fetch;
          const { spawnSync } = require('child_process');

          const REG = process.env.AZURE_REGISTRY;
          if (!REG) throw new Error('AZURE_REGISTRY missing');

          async function postForm(url, form) {
            const body = new URLSearchParams(form);
            const r = await fetch(url, { method: 'POST', headers: {'Content-Type':'application/x-www-form-urlencoded'}, body });
            if (!r.ok) throw new Error(`HTTP ${r.status} ${url}: ${await r.text()}`);
            return await r.json();
          }
          const b64url = s => {
            s = s.replace(/-/g,'+').replace(/_/g,'/'); const pad = s.length % 4; if (pad) s += '='.repeat(4-pad);
            return Buffer.from(s, 'base64').toString();
          };

          let aadToken = null;
          let tenant = process.env.AZURE_TENANT_ID || '';

          // --- 1) AKS Workload Identity (token file + client_id + tenant) ---
          const wiFile = process.env.AZURE_FEDERATED_TOKEN_FILE;
          if (!aadToken && wiFile && fs.existsSync(wiFile) &&
              process.env.AZURE_CLIENT_ID && process.env.AZURE_TENANT_ID) {
            core.info('Using AKS Workload Identity');
            const wi = fs.readFileSync(wiFile, 'utf8').trim();
            const res = await postForm(`https://login.microsoftonline.com/${process.env.AZURE_TENANT_ID}/oauth2/v2.0/token`, {
              client_id: process.env.AZURE_CLIENT_ID,
              grant_type: 'client_credentials',
              scope: 'https://management.azure.com/.default',
              client_assertion_type: 'urn:ietf:params:oauth:client-assertion-type:jwt-bearer',
              client_assertion: wi,
            });
            aadToken = res.access_token;
            tenant = process.env.AZURE_TENANT_ID;
          }

          // --- 2) Node MSI (IMDS). UAMI if AZURE_CLIENT_ID is set; else SAI ---
          if (!aadToken) {
            core.info('Trying IMDS (MSI)');
            const params = new URLSearchParams({
              'api-version': '2018-02-01',
              resource: 'https://management.azure.com/'
            });
            if (process.env.AZURE_CLIENT_ID) params.set('client_id', process.env.AZURE_CLIENT_ID);
            try {
              const r = await fetch(`http://169.254.169.254/metadata/identity/oauth2/token?${params}`, {
                headers: { 'Metadata': 'true' }
              });
              if (r.ok) {
                const j = await r.json();
                aadToken = j.access_token;
                // derive tenant from tid claim
                const payload = JSON.parse(b64url(aadToken.split('.')[1]));
                tenant = payload.tid || tenant;
                core.info('Using Node MSI');
              }
            } catch (_) {}
          }

          // --- 3) Client secret fallback (service principal) ---
          if (!aadToken && process.env.AAD_CLIENT_ID && process.env.AAD_CLIENT_SECRET && process.env.AAD_TENANT_ID) {
            core.info('Using Client Credentials (secret fallback)');
            const res = await postForm(`https://login.microsoftonline.com/${process.env.AAD_TENANT_ID}/oauth2/v2.0/token`, {
              client_id: process.env.AAD_CLIENT_ID,
              client_secret: process.env.AAD_CLIENT_SECRET,
              grant_type: 'client_credentials',
              scope: 'https://management.azure.com/.default'
            });
            aadToken = res.access_token;
            tenant = process.env.AAD_TENANT_ID;
          }

          if (!aadToken) throw new Error('No Azure auth available (WI/MSI/secret)');

          core.setSecret(aadToken);

          // --- ACR OAuth2: AAD access_token -> refresh_token ---
          const refresh = await postForm(`https://${REG}/oauth2/exchange`, {
            service: REG,
            tenant,
            grant_type: 'access_token',
            access_token: aadToken
          });
          const refreshToken = refresh.refresh_token;
          if (!refreshToken) throw new Error('Failed to get ACR refresh_token');
          core.setSecret(refreshToken);

          // --- ACR OAuth2: refresh_token -> access_token with push/pull scope ---
          // Use a wildcard so any repo you push in this job is authorized.
          const access = await postForm(`https://${REG}/oauth2/token`, {
            service: REG,
            grant_type: 'refresh_token',
            refresh_token: refreshToken,
            scope: 'repository:*:pull,push'
          });
          const accessToken = access.access_token;
          if (!accessToken) throw new Error('Failed to get ACR access_token');
          core.setSecret(accessToken);

          // Docker login on the host (BuildKit will reuse these creds)
          const p = spawnSync('docker', ['login', REG, '--username', '00000000-0000-0000-0000-000000000000', '--password-stdin'], {
            input: accessToken, stdio: ['pipe','inherit','inherit']
          });
          if (p.status) throw new Error(`docker login failed: ${p.status}`);
          core.info(`✅ Logged in to ${REG} (scope: repository:*:pull,push)`);



    # ── Derive AWS account & region from your registry host ───────────────────────
    - name: Derive AWS account/region from registry
      id: awsreg
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      shell: bash
      run: |
        set -euo pipefail
        REG="${{ steps.env.outputs.aws_registry }}"   # e.g. 123456789012.dkr.ecr.eu-west-1.amazonaws.com
        [[ -n "$REG" ]] || { echo "aws_registry missing"; exit 1; }
        ACCOUNT="${REG%%.*}"
        REGION="$(echo "$REG" | cut -d. -f4)"         # eu-west-1
        echo "account=$ACCOUNT" >> "$GITHUB_OUTPUT"
        echo "region=$REGION"  >> "$GITHUB_OUTPUT"

    # ── Detect Pod Identity/IMDS vs static keys ────────────────────────────────
    - name: Detect AWS credential source
      id: awsauth
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      shell: bash
      run: |
        set -euo pipefail
        export NO_PROXY=169.254.170.23,169.254.169.254

        MODE="static"

        if [ -z "${{ inputs.aws_access_key_id }}" ]; then
          # try Pod Identity container creds
          if [ -n "${AWS_CONTAINER_CREDENTIALS_FULL_URI:-}" ] && [ -f "${AWS_CONTAINER_AUTHORIZATION_TOKEN_FILE:-}" ]; then
            TOKEN="$(tr -d '\r\n' < "$AWS_CONTAINER_AUTHORIZATION_TOKEN_FILE" || true)"
            if [ -n "$TOKEN" ]; then
              code=$(curl -s -o /dev/null -w '%{http_code}' \
                -H "Authorization: Bearer $TOKEN" \
                "$AWS_CONTAINER_CREDENTIALS_FULL_URI" || true)
              if [ "$code" = "200" ]; then MODE="identity"; fi
            fi
          fi

          # fallback: IMDS (node role or PI agent)
          if [ "$MODE" != "identity" ]; then
            tok=$(curl -s -m 2 -X PUT -H 'X-aws-ec2-metadata-token-ttl-seconds: 60' \
              http://169.254.169.254/latest/api/token || true)
            role=$(curl -s -m 2 ${tok:+-H "X-aws-ec2-metadata-token: $tok"} \
              http://169.254.169.254/latest/meta-data/iam/security-credentials/ || true)
            if [ -n "$role" ]; then MODE="identity"; fi
          fi
        fi

        echo "mode=$MODE" >> "$GITHUB_OUTPUT"

    # ── Ensure ECR repository exists ──────────────────────────────────────────
    - name: Ensure ECR repository exists
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-region: ${{ steps.awsreg.outputs.region }}
        role-to-assume: ${{ steps.awsauth.outputs.mode == 'identity' && '' || '' }} # optional if using OIDC
        aws-access-key-id:     ${{ steps.awsauth.outputs.mode == 'static' && inputs.aws_access_key_id || '' }}
        aws-secret-access-key: ${{ steps.awsauth.outputs.mode == 'static' && inputs.aws_secret_access_key || '' }}
        aws-session-token:     ${{ steps.awsauth.outputs.mode == 'static' && inputs.aws_session_token || '' }}
    - run: |
        aws ecr describe-repositories --repository-names "${{ inputs.image }}" \
          || aws ecr create-repository --repository-name "${{ inputs.image }}" \
            --image-scanning-configuration scanOnPush=true

    # ── ECR login with whichever creds were chosen ─────────────────────────────
    - uses: aws-actions/amazon-ecr-login@v2
      name: 🔐 ECR login (identity/IMDS)
      if: ${{ (inputs.push == 'aws' || inputs.push == 'both') && steps.awsauth.outputs.mode == 'identity' }}
      env:
        AWS_REGION: ${{ steps.awsreg.outputs.region }}
      with:
        registries: ${{ steps.awsreg.outputs.account }}

    - uses: aws-actions/amazon-ecr-login@v2
      name: 🔐 ECR login (static keys)
      if: ${{ (inputs.push == 'aws' || inputs.push == 'both') && steps.awsauth.outputs.mode == 'static' }}
      env:
        AWS_REGION:            ${{ steps.awsreg.outputs.region }}
        AWS_ACCESS_KEY_ID:     ${{ inputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        AWS_SESSION_TOKEN:     ${{ inputs.aws_session_token }}
      with:
        registries: ${{ steps.awsreg.outputs.account }}











    - name: normalize-inputs
      id: normalize
      uses: actions/github-script@v7
      env:
        IMAGE_DETAILS: ${{ inputs.image_details }}
        SINGLE_IMAGE:  ${{ inputs.image }}
        SINGLE_DF:     ${{ inputs.build_file }}
        SINGLE_CTX:    ${{ inputs.path }}
      with:
        script: |
          const raw   = (process.env.IMAGE_DETAILS || '').trim();
          const image = (process.env.SINGLE_IMAGE  || '').trim();
          const df    = (process.env.SINGLE_DF     || '').trim();
          const ctx   = (process.env.SINGLE_CTX    || '.').trim() || '.';

          let items;
          if (raw) {
            items = JSON.parse(raw);
            if (!Array.isArray(items)) throw new Error('image_details must be a JSON array');
          } else if (image && df) {
            items = [{ context: ctx, build_file: df, image_name: image }];
          } else {
            throw new Error('Provide either inputs.image_details (JSON array) OR both inputs.image and inputs.build_file (and optional inputs.path).');
          }

          items.forEach((it, i) => {
            const miss = ['context','build_file','image_name'].filter(k => !it?.[k]);
            if (miss.length) throw new Error(`items[${i}] missing: ${miss.join(', ')}`);
          });

          core.setOutput('items', JSON.stringify(items));
          core.setOutput('count', String(items.length));

          // 🔎 Print normalized inputs for debugging
          core.startGroup('normalized items');
          core.info(JSON.stringify(items, null, 2));
          core.info(`count: ${items.length}`);
          core.endGroup();

    - name: 🐳 Set up Docker Buildx
      if: "!contains(runner.name, 'self-hosted')"
      uses: docker/setup-buildx-action@v3


    - name: 🔧 Register remote BuildKit with buildx
      if: "contains(runner.name, 'self-hosted')"
      shell: bash
      run: |
        docker buildx create --name remote-builder --driver remote tcp://127.0.0.1:12345
        docker buildx use remote-builder
        docker buildx inspect --bootstrap

   



    # Detect which cloud this runner is on (self-hosted ⇒ aws/azure, GH-hosted ⇒ unknown)
    - name: Detect cloud
      id: cloud
      uses: gitopsmanager/detect-cloud@main
      with:
        timeout-ms: 800


    # Set cache to ONE registry only (prefer the detected cloud)
    - name: set-cache-to-provider
      id: enhance
      uses: actions/github-script@v7
      env:
        ITEMS:    ${{ steps.normalize.outputs.items }}
        PROVIDER: ${{ steps.cloud.outputs.provider }}     # aws | azure | unknown
        PUSH:     ${{ inputs.push }}                      # none | aws | azure | both
        MODE:     ${{ inputs.buildkit_cache_mode }}       # none | min | max
        AWS_REG:  ${{ steps.env.outputs.aws_registry }}
        AZ_REG:   ${{ steps.env.outputs.azure_registry }}
      with:
        script: |
          const items = JSON.parse(process.env.ITEMS);
          const provider = (process.env.PROVIDER || 'unknown').toLowerCase();
          const PUSH = (process.env.PUSH || 'none').toLowerCase();
          const MODE = (process.env.MODE || 'none').toLowerCase();
          const AWS  = process.env.AWS_REG || '';
          const AZ   = process.env.AZ_REG  || '';

          // Choose exactly ONE cache registry
          let cacheCloud = '';
          if (provider === 'aws' || provider === 'azure') {
            cacheCloud = provider;                      // self-hosted, detected cloud
          } else {
            // GH-hosted or blocked IMDS: pick a sensible fallback based on what we're pushing
            if (PUSH === 'azure' || PUSH === 'both') cacheCloud = 'azure';
            else if (PUSH === 'aws')                cacheCloud = 'aws';
            else cacheCloud = ''; // not pushing anywhere; skip caching
          }

          const pick = (reg, img, mode) => reg ? {
            from: [`type=registry,ref=${reg}/${img}:buildcache`],
            to:   [`type=registry,ref=${reg}/${img}:buildcache,mode=${mode},ignore-error=true`]
          } : { from: [], to: [] };

          const out = items.map(it => {
            let cacheFrom = [], cacheTo = [];
            if (MODE !== 'none' && PUSH !== 'none') {
              if (cacheCloud === 'azure') ({ from: cacheFrom, to: cacheTo } = pick(AZ, it.image_name, MODE));
              if (cacheCloud === 'aws')   ({ from: cacheFrom, to: cacheTo } = pick(AWS, it.image_name, MODE));
            }
            return { ...it, cacheFrom, cacheTo };
          });

          core.setOutput('items', JSON.stringify(out));
          core.setOutput('count', String(out.length));

    - name: generate-bake
      id: bakefile
      if: ${{ steps.enhance.outputs.count != '0' }}
      uses: actions/github-script@v7
      env:
        ITEMS:    ${{ steps.enhance.outputs.items }}
        PUSH:     ${{ inputs.push }}
        AWS_REG:  ${{ steps.env.outputs.aws_registry }}
        AZ_REG:   ${{ steps.env.outputs.azure_registry }}
        USER_TAG: ${{ inputs.tag }}   # optional; may be empty
      with:
        script: |
          const fs = require('fs');
          const path = require('path');

          const items = JSON.parse(process.env.ITEMS || '[]');
          const PUSH  = (process.env.PUSH || 'none').toLowerCase();
          const AWS   = process.env.AWS_REG || '';
          const AZ    = process.env.AZ_REG  || '';
          const ROOT  = process.env.GITHUB_WORKSPACE || process.cwd();
          const toPosix = p => p.replace(/\\/g, '/');

          // Always present for both workflow_dispatch and triggered runs
          const RUN_TAG  = process.env.GITHUB_RUN_ID;
          const USER_TAG = process.env.USER_TAG || '';
          const TAGS_TO_USE = USER_TAG ? [RUN_TAG, USER_TAG] : [RUN_TAG];

          const target = {}, targets = [];

          items.forEach((it, i) => {
            const name = `t${i}`;
            const tags = [];

            if ((PUSH === 'aws' || PUSH === 'both') && AWS) TAGS_TO_USE.forEach(t => tags.push(`${AWS}/${it.image_name}:${t}`));
            if ((PUSH === 'azure' || PUSH === 'both') && AZ) TAGS_TO_USE.forEach(t => tags.push(`${AZ}/${it.image_name}:${t}`));
            if (PUSH === 'none' && it.image_name)           TAGS_TO_USE.forEach(t => tags.push(`${it.image_name}:${t}`));

            // Context: if relative -> join with $GITHUB_WORKSPACE
            const ctxInput = it.context || '.';
            const ctxPath  = path.isAbsolute(ctxInput) ? ctxInput : path.join(ROOT, ctxInput);

            // Dockerfile: if relative -> join with $GITHUB_WORKSPACE (do NOT base on context)
            const dfInput  = it.build_file || 'Dockerfile';
            const dfPath   = path.isAbsolute(dfInput) ? dfInput : path.join(ROOT, dfInput);

            target[name] = {
              context:   toPosix(ctxPath),
              dockerfile: toPosix(dfPath),
              tags
            };

            if (it.cacheFrom?.length) target[name]['cache-from'] = it.cacheFrom;
            if (it.cacheTo?.length)   target[name]['cache-to']   = it.cacheTo;

            targets.push(name);
          });

          const bake = { group: { default: { targets } }, target };
          fs.writeFileSync('docker-bake.json', JSON.stringify(bake, null, 2));
          core.startGroup('docker-bake.json');
          core.info(fs.readFileSync('docker-bake.json','utf8'));
          core.endGroup();



    # Bake with live workspace (includes files generated earlier)
    - name: bake
      uses: docker/bake-action@v6
      with:
        source: .
        files: docker-bake.json
        push: ${{ inputs.push != 'none' }}
        # builder: remote-builder

