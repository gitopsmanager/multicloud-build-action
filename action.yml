# action.yml
name: Multicloud Build (composite)
description: >
  Build and push Docker images to AWS ECR or Azure ACR using Docker/BuildKit.
  Supports AKS Workload Identity, Azure MSI/client secret, and EKS Pod Identity or static keys.
  Loads default registries from a CD repo, optional BuildKit caching, and ECR repo auto-create.

author: Affinity7 Consulting Ltd
branding:
  icon: package
  color: blue

inputs:
  image_details:
    description: |
      JSON array of {context, build_file, image_name} or specify a single build with separate parmeters. 
      Example:
      [
        {"context":"./services/a","build_file":"Dockerfile","image_name":"team/svc-a"},
        {"context":"./services/b","build_file":"Dockerfile","image_name":"team/svc-b"}
      ]
    required: false
    type: string
  path:
    description: "Path to the build context - full path or relative to $GITHUB_WORKSPACE."
    required: false
    default: "."
  image:
    description: "Image name (e.g. gitopsmanager)"
    required: true
  tag:
    description: "Tag for the image"
    required: false
    default: ""
  build_file:
    description: "Dockerfile - full path or relative to $GITHUB_WORKSPACE."
    required: false
    default: "Dockerfile"
  extra_args:
    description: "Additional buildkit args"
    required: false
    default: ""

  cd_repo:
    description: "CD repo (owner/repo) with cd/config/env-map.yaml providing default registries"
    required: true

  push:
    description: "Where to push the image (aws | azure | both | none)"
    required: false
    default: "none"

  buildkit_cache_mode:
    description: "BuildKit cache mode (min|max|none). Caches only to the current cloud."
    required: false
    default: "max"

  # GitHub App for CD repo checkout
  cd_app_id:
    description: "GitHub App ID for CD repo access"
    required: true
  cd_app_private_key:
    description: "GitHub App private key (PEM) for CD repo access"
    required: true

  # Azure credentials (used if not on AKS WI/MSI)
  azure_client_id:
    description: "Azure App/Identity client ID"
    required: false
    default: ""
  azure_client_secret:
    description: "Azure client secret"
    required: false
    default: ""
  azure_tenant_id:
    description: "Azure tenant ID"
    required: false
    default: ""

  # AWS credentials (used if not on EKS Pod Identity)
  aws_access_key_id:
    description: "AWS access key ID"
    required: false
    default: ""
  aws_secret_access_key:
    description: "AWS secret access key"
    required: false
    default: ""

runs:
  using: composite
  steps:

    - name: 🔑 Generate GitHub App token
      id: generate_token
      uses: tibdex/github-app-token@v2.1.0
      with:
        app_id: ${{ inputs.cd_app_id }}
        private_key: ${{ inputs.cd_app_private_key }}
        installation_retrieval_mode: repository
        installation_retrieval_payload: ${{ inputs.cd_repo }}
        revoke: true



    - name: 📂 Checkout CD repo
      uses: actions/checkout@v4
      with:
        repository: ${{ inputs.cd_repo }}
        token: ${{ steps.generate_token.outputs.token }}
        path: cd

    - name: 📑 Load environment config
      id: env
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');

          const cfg = JSON.parse(
            fs.readFileSync(path.join(process.env.GITHUB_WORKSPACE, 'cd/config/env-map.json'), 'utf8')
          );
          core.setOutput('aws_registry',   cfg.build.aws_default_container_registry);
          core.setOutput('azure_registry', cfg.build.azure_default_container_registry);

    - name: 🔐 ACR login via REST (WI → MSI → secret; no az)
      if: ${{ inputs.push == 'azure' || inputs.push == 'both' }}
      uses: actions/github-script@v7
      env:
        # Your registry host, e.g. "af7gitops.azurecr.io"
        AZURE_REGISTRY: ${{ steps.env.outputs.azure_registry }}
        # Optional client-secret fallback (only if you support it)
        AAD_CLIENT_ID:     ${{ inputs.azure_client_id }}
        AAD_CLIENT_SECRET: ${{ inputs.azure_client_secret }}
        AAD_TENANT_ID:     ${{ inputs.azure_tenant_id }}
      with:
        script: |
          const fs = require('fs');
          const fetch = global.fetch;
          const { spawnSync } = require('child_process');

          const REG = process.env.AZURE_REGISTRY;
          if (!REG) throw new Error('AZURE_REGISTRY missing');

          async function postForm(url, form) {
            const body = new URLSearchParams(form);
            const r = await fetch(url, { method: 'POST', headers: {'Content-Type':'application/x-www-form-urlencoded'}, body });
            if (!r.ok) throw new Error(`HTTP ${r.status} ${url}: ${await r.text()}`);
            return await r.json();
          }
          const b64url = s => {
            s = s.replace(/-/g,'+').replace(/_/g,'/'); const pad = s.length % 4; if (pad) s += '='.repeat(4-pad);
            return Buffer.from(s, 'base64').toString();
          };

          let aadToken = null;
          let tenant = process.env.AZURE_TENANT_ID || '';

          // --- 1) AKS Workload Identity (token file + client_id + tenant) ---
          const wiFile = process.env.AZURE_FEDERATED_TOKEN_FILE;
          if (!aadToken && wiFile && fs.existsSync(wiFile) &&
              process.env.AZURE_CLIENT_ID && process.env.AZURE_TENANT_ID) {
            core.info('Using AKS Workload Identity');
            const wi = fs.readFileSync(wiFile, 'utf8').trim();
            const res = await postForm(`https://login.microsoftonline.com/${process.env.AZURE_TENANT_ID}/oauth2/v2.0/token`, {
              client_id: process.env.AZURE_CLIENT_ID,
              grant_type: 'client_credentials',
              scope: 'https://management.azure.com/.default',
              client_assertion_type: 'urn:ietf:params:oauth:client-assertion-type:jwt-bearer',
              client_assertion: wi,
            });
            aadToken = res.access_token;
            tenant = process.env.AZURE_TENANT_ID;
          }

          // --- 2) Node MSI (IMDS). UAMI if AZURE_CLIENT_ID is set; else SAI ---
          if (!aadToken) {
            core.info('Trying IMDS (MSI)');
            const params = new URLSearchParams({
              'api-version': '2018-02-01',
              resource: 'https://management.azure.com/'
            });
            if (process.env.AZURE_CLIENT_ID) params.set('client_id', process.env.AZURE_CLIENT_ID);
            try {
              const r = await fetch(`http://169.254.169.254/metadata/identity/oauth2/token?${params}`, {
                headers: { 'Metadata': 'true' }
              });
              if (r.ok) {
                const j = await r.json();
                aadToken = j.access_token;
                // derive tenant from tid claim
                const payload = JSON.parse(b64url(aadToken.split('.')[1]));
                tenant = payload.tid || tenant;
                core.info('Using Node MSI');
              }
            } catch (_) {}
          }

          // --- 3) Client secret fallback (service principal) ---
          if (!aadToken && process.env.AAD_CLIENT_ID && process.env.AAD_CLIENT_SECRET && process.env.AAD_TENANT_ID) {
            core.info('Using Client Credentials (secret fallback)');
            const res = await postForm(`https://login.microsoftonline.com/${process.env.AAD_TENANT_ID}/oauth2/v2.0/token`, {
              client_id: process.env.AAD_CLIENT_ID,
              client_secret: process.env.AAD_CLIENT_SECRET,
              grant_type: 'client_credentials',
              scope: 'https://management.azure.com/.default'
            });
            aadToken = res.access_token;
            tenant = process.env.AAD_TENANT_ID;
          }

          if (!aadToken) throw new Error('No Azure auth available (WI/MSI/secret)');

          core.setSecret(aadToken);

          // --- ACR OAuth2: AAD access_token -> refresh_token ---
          const refresh = await postForm(`https://${REG}/oauth2/exchange`, {
            service: REG,
            tenant,
            grant_type: 'access_token',
            access_token: aadToken
          });
          const refreshToken = refresh.refresh_token;
          if (!refreshToken) throw new Error('Failed to get ACR refresh_token');
          core.setSecret(refreshToken);

          // --- ACR OAuth2: refresh_token -> access_token with push/pull scope ---
          // Use a wildcard so any repo you push in this job is authorized.
          const access = await postForm(`https://${REG}/oauth2/token`, {
            service: REG,
            grant_type: 'refresh_token',
            refresh_token: refreshToken,
            scope: 'repository:*:pull,push'
          });
          const accessToken = access.access_token;
          if (!accessToken) throw new Error('Failed to get ACR access_token');
          core.setSecret(accessToken);

          // Docker login on the host (BuildKit will reuse these creds)
          const p = spawnSync('docker', ['login', REG, '--username', '00000000-0000-0000-0000-000000000000', '--password-stdin'], {
            input: accessToken, stdio: ['pipe','inherit','inherit']
          });
          if (p.status) throw new Error(`docker login failed: ${p.status}`);
          core.info(`✅ Logged in to ${REG} (scope: repository:*:pull,push)`);



    # ── Derive AWS account & region from your registry host ───────────────────────
    - name: Derive AWS account/region from registry
      id: awsreg
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      shell: bash
      run: |
        set -euo pipefail
        REG="${{ steps.env.outputs.aws_registry }}"   # e.g. 123456789012.dkr.ecr.eu-west-1.amazonaws.com
        [[ -n "$REG" ]] || { echo "aws_registry missing"; exit 1; }
        ACCOUNT="${REG%%.*}"
        REGION="$(echo "$REG" | cut -d. -f4)"         # eu-west-1
        echo "account=$ACCOUNT" >> "$GITHUB_OUTPUT"
        echo "region=$REGION"  >> "$GITHUB_OUTPUT"

    # ── Ensure the ECR repository exists (no aws cli; SigV4 via github-script) ────
    - name: Ensure ECR repository exists
      if: ${{ inputs.push == 'aws' || inputs.push == 'both' }}
      uses: actions/github-script@v7
      env:
        AWS_REGION:  ${{ steps.awsreg.outputs.region }}
        ECR_REPO:    ${{ inputs.image }}                     # e.g. team/app
        # optional static keys — use NON-standard names so we don't clobber identity
        STATIC_AWS_ACCESS_KEY_ID:     ${{ inputs.aws_access_key_id }}
        STATIC_AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        STATIC_AWS_SESSION_TOKEN:     ${{ inputs.aws_session_token }}
      with:
        script: |
          const crypto = require('crypto');
          const fetch = global.fetch;

          const region = process.env.AWS_REGION;
          const repo   = process.env.ECR_REPO;
          if (!region) throw new Error('AWS_REGION missing');
          if (!repo)   throw new Error('ECR_REPO missing');

          const host = `api.ecr.${region}.amazonaws.com`;

          const sha256Hex = s => crypto.createHash('sha256').update(s,'utf8').digest('hex');
          const hmac = (k,d) => crypto.createHmac('sha256', k).update(d,'utf8').digest();
          const hmacHex = (k,d) => crypto.createHmac('sha256', k).update(d,'utf8').digest('hex');

          async function timedFetch(url, opts = {}, ms = 1200) {
            const ac = new AbortController(); const t = setTimeout(()=>ac.abort(), ms);
            try { return await fetch(url, { ...opts, signal: ac.signal }); }
            finally { clearTimeout(t); }
          }

          async function getPodIdentityCreds() {
            const full = process.env.AWS_CONTAINER_CREDENTIALS_FULL_URI;
            const rel  = process.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI;
            const uri  = full || (rel ? `http://169.254.170.2${rel}` : '');
            if (!uri) return null;
            const headers = {};
            if (process.env.AWS_CONTAINER_AUTHORIZATION_TOKEN)
              headers['Authorization'] = `Bearer ${process.env.AWS_CONTAINER_AUTHORIZATION_TOKEN}`;
            try {
              const r = await timedFetch(uri, { headers }, 1500);
              if (!r.ok) return null;
              const j = await r.json();
              return { accessKeyId: j.AccessKeyId, secretAccessKey: j.SecretAccessKey, sessionToken: j.Token };
            } catch { return null; }
          }

          async function getImdsCreds() {
            try {
              const tRes = await timedFetch('http://169.254.169.254/latest/api/token', {
                method: 'PUT', headers: {'X-aws-ec2-metadata-token-ttl-seconds':'21600'}
              }, 900);
              const token = tRes.ok ? await tRes.text() : '';
              const h = token ? {'X-aws-ec2-metadata-token': token} : {};
              const roleRes = await timedFetch('http://169.254.169.254/latest/meta-data/iam/security-credentials/', { headers: h }, 900);
              if (!roleRes.ok) return null;
              const role = (await roleRes.text()).trim();
              if (!role) return null;
              const credRes = await timedFetch(`http://169.254.169.254/latest/meta-data/iam/security-credentials/${role}`, { headers: h }, 900);
              if (!credRes.ok) return null;
              const c = await credRes.json();
              return { accessKeyId: c.AccessKeyId, secretAccessKey: c.SecretAccessKey, sessionToken: c.Token };
            } catch { return null; }
          }

          function getStaticCreds() {
            const ak = process.env.STATIC_AWS_ACCESS_KEY_ID || '';
            const sk = process.env.STATIC_AWS_SECRET_ACCESS_KEY || '';
            const st = process.env.STATIC_AWS_SESSION_TOKEN || '';
            return (ak && sk) ? { accessKeyId: ak, secretAccessKey: sk, sessionToken: st || undefined } : null;
          }

          async function ecrCall(target, payload, creds) {
            const body = JSON.stringify(payload);
            const now = new Date();
            const amzdate = now.toISOString().replace(/[-:]/g,'').replace(/\.\d{3}Z$/,'Z'); // YYYYMMDDTHHMMSSZ
            const datestamp = amzdate.slice(0,8);
            const service = 'ecr';

            const hdrs = {
              'content-type': 'application/x-amz-json-1.1',
              'host': host,
              'x-amz-date': amzdate,
              'x-amz-target': `AmazonEC2ContainerRegistry_V20150921.${target}`,
            };
            if (creds.sessionToken) hdrs['x-amz-security-token'] = creds.sessionToken;

            const signedNames = Object.keys(hdrs).sort();
            const canonicalHeaders = signedNames.map(k => `${k}:${hdrs[k]}\n`).join('');
            const signedHeaders = signedNames.join(';');
            const canonicalRequest = ['POST','/','',canonicalHeaders,signedHeaders,sha256Hex(body)].join('\n');

            const algorithm = 'AWS4-HMAC-SHA256';
            const scope = `${datestamp}/${region}/${service}/aws4_request`;
            const stringToSign = [algorithm, amzdate, scope, sha256Hex(canonicalRequest)].join('\n');

            const kDate = hmac('AWS4' + creds.secretAccessKey, datestamp);
            const kRegion = hmac(kDate, region);
            const kService = hmac(kRegion, service);
            const kSigning = hmac(kService, 'aws4_request');
            const signature = hmacHex(kSigning, stringToSign);

            const reqHeaders = {
              'Content-Type': 'application/x-amz-json-1.1',
              'X-Amz-Target': hdrs['x-amz-target'],
              'X-Amz-Date':   hdrs['x-amz-date'],
              'Authorization': `${algorithm} Credential=${creds.accessKeyId}/${scope}, SignedHeaders=${signedHeaders}, Signature=${signature}`,
              'Host': host
            };
            if (creds.sessionToken) reqHeaders['X-Amz-Security-Token'] = creds.sessionToken;

            const res = await fetch(`https://${host}/`, { method:'POST', headers:reqHeaders, body });
            const text = await res.text(); let json; try { json = JSON.parse(text); } catch {}
            if (!res.ok) throw new Error(`ECR ${target} ${res.status} ${(res.headers.get('x-amzn-errortype')||'')} ${text}`);
            return json;
          }

          // Resolve creds: Pod Identity → node IMDS → static keys
          let creds = await getPodIdentityCreds();
          if (creds) core.info('Using EKS Pod Identity credentials');
          if (!creds) { creds = await getImdsCreds(); if (creds) core.info('Using node IMDS credentials'); }
          if (!creds) { creds = getStaticCreds();     if (creds) core.info('Using static AWS keys'); }
          if (!creds) throw new Error('No AWS credentials available (Pod Identity, node role, or keys)');

          // Ensure repo exists
          try {
            await ecrCall('DescribeRepositories', { repositoryNames: [repo] }, creds);
            core.info(`ECR repository '${repo}' already exists.`);
          } catch (e) {
            if (String(e.message).includes('RepositoryNotFoundException')) {
              core.info(`Creating ECR repository '${repo}' (scanOnPush=true)`);
              await ecrCall('CreateRepository', {
                repositoryName: repo,
                imageScanningConfiguration: { scanOnPush: true }
              }, creds);
            } else {
              throw e;
            }
          }

    # login with pod identity / node role
    - uses: aws-actions/amazon-ecr-login@v2
      name: 🔐 ECR login (identity/IMDS)
      if: ${{ (inputs.push == 'aws' || inputs.push == 'both') && inputs.aws_access_key_id == '' }}
      env:
        AWS_REGION: ${{ steps.awsreg.outputs.region }}
      with:
        registries: ${{ steps.awsreg.outputs.account }}

    # login with static keys (fallback)
    - uses: aws-actions/amazon-ecr-login@v2
      name: 🔐 ECR login (static keys)
      if: ${{ (inputs.push == 'aws' || inputs.push == 'both') && inputs.aws_access_key_id != '' }}
      env:
        AWS_REGION:            ${{ steps.awsreg.outputs.region }}
        AWS_ACCESS_KEY_ID:     ${{ inputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        AWS_SESSION_TOKEN:     ${{ inputs.aws_session_token }}
      with:
        registries: ${{ steps.awsreg.outputs.account }}









    - name: normalize-inputs
      id: normalize
      uses: actions/github-script@v7
      env:
        IMAGE_DETAILS: ${{ inputs.image_details }}
        SINGLE_IMAGE:  ${{ inputs.image }}
        SINGLE_DF:     ${{ inputs.build_file }}
        SINGLE_CTX:    ${{ inputs.path }}
      with:
        script: |
          const raw   = (process.env.IMAGE_DETAILS || '').trim();
          const image = (process.env.SINGLE_IMAGE  || '').trim();
          const df    = (process.env.SINGLE_DF     || '').trim();
          const ctx   = (process.env.SINGLE_CTX    || '.').trim() || '.';

          let items;
          if (raw) {
            items = JSON.parse(raw);
            if (!Array.isArray(items)) throw new Error('image_details must be a JSON array');
          } else if (image && df) {
            items = [{ context: ctx, build_file: df, image_name: image }];
          } else {
            throw new Error('Provide either inputs.image_details (JSON array) OR both inputs.image and inputs.build_file (and optional inputs.path).');
          }

          items.forEach((it, i) => {
            const miss = ['context','build_file','image_name'].filter(k => !it?.[k]);
            if (miss.length) throw new Error(`items[${i}] missing: ${miss.join(', ')}`);
          });

          core.setOutput('items', JSON.stringify(items));
          core.setOutput('count', String(items.length));

          // 🔎 Print normalized inputs for debugging
          core.startGroup('normalized items');
          core.info(JSON.stringify(items, null, 2));
          core.info(`count: ${items.length}`);
          core.endGroup();

   
    - name: 🐳 Set up Docker Buildx
      if: "!contains(runner.name, 'self-hosted')"
      uses: docker/setup-buildx-action@v3

    - name: 🔧 Set up sidecar BuildKit builder
      if: "contains(runner.name, 'self-hosted')"
      shell: bash
      run: |
        docker buildx create --name remote-builder --driver remote --use tcp://localhost:12345
        docker buildx inspect --bootstrap


    # Detect which cloud this runner is on (self-hosted ⇒ aws/azure, GH-hosted ⇒ unknown)
    - name: Detect cloud
      id: cloud
      uses: gitopsmanager/detect-cloud@main
      with:
        timeout-ms: 800


    # Set cache to ONE registry only (prefer the detected cloud)
    - name: set-cache-to-provider
      id: enhance
      uses: actions/github-script@v7
      env:
        ITEMS:    ${{ steps.normalize.outputs.items }}
        PROVIDER: ${{ steps.cloud.outputs.provider }}     # aws | azure | unknown
        PUSH:     ${{ inputs.push }}                      # none | aws | azure | both
        MODE:     ${{ inputs.buildkit_cache_mode }}       # none | min | max
        AWS_REG:  ${{ steps.env.outputs.aws_registry }}
        AZ_REG:   ${{ steps.env.outputs.azure_registry }}
      with:
        script: |
          const items = JSON.parse(process.env.ITEMS);
          const provider = (process.env.PROVIDER || 'unknown').toLowerCase();
          const PUSH = (process.env.PUSH || 'none').toLowerCase();
          const MODE = (process.env.MODE || 'none').toLowerCase();
          const AWS  = process.env.AWS_REG || '';
          const AZ   = process.env.AZ_REG  || '';

          // Choose exactly ONE cache registry
          let cacheCloud = '';
          if (provider === 'aws' || provider === 'azure') {
            cacheCloud = provider;                      // self-hosted, detected cloud
          } else {
            // GH-hosted or blocked IMDS: pick a sensible fallback based on what we're pushing
            if (PUSH === 'azure' || PUSH === 'both') cacheCloud = 'azure';
            else if (PUSH === 'aws')                cacheCloud = 'aws';
            else cacheCloud = ''; // not pushing anywhere; skip caching
          }

          const pick = (reg, img, mode) => reg ? {
            from: [`type=registry,ref=${reg}/${img}:buildcache`],
            to:   [`type=registry,ref=${reg}/${img}:buildcache,mode=${mode},ignore-error=true`]
          } : { from: [], to: [] };

          const out = items.map(it => {
            let cacheFrom = [], cacheTo = [];
            if (MODE !== 'none' && PUSH !== 'none') {
              if (cacheCloud === 'azure') ({ from: cacheFrom, to: cacheTo } = pick(AZ, it.image_name, MODE));
              if (cacheCloud === 'aws')   ({ from: cacheFrom, to: cacheTo } = pick(AWS, it.image_name, MODE));
            }
            return { ...it, cacheFrom, cacheTo };
          });

          core.setOutput('items', JSON.stringify(out));
          core.setOutput('count', String(out.length));

    - name: generate-bake
      id: bakefile
      if: ${{ steps.enhance.outputs.count != '0' }}
      uses: actions/github-script@v7
      env:
        ITEMS:    ${{ steps.enhance.outputs.items }}
        PUSH:     ${{ inputs.push }}
        AWS_REG:  ${{ steps.env.outputs.aws_registry }}
        AZ_REG:   ${{ steps.env.outputs.azure_registry }}
        USER_TAG: ${{ inputs.tag }}   # optional; may be empty
      with:
        script: |
          const fs = require('fs');
          const path = require('path');

          const items = JSON.parse(process.env.ITEMS || '[]');
          const PUSH  = (process.env.PUSH || 'none').toLowerCase();
          const AWS   = process.env.AWS_REG || '';
          const AZ    = process.env.AZ_REG  || '';
          const ROOT  = process.env.GITHUB_WORKSPACE || process.cwd();
          const toPosix = p => p.replace(/\\/g, '/');

          // Always present for both workflow_dispatch and triggered runs
          const RUN_TAG  = process.env.GITHUB_RUN_ID;
          const USER_TAG = process.env.USER_TAG || '';
          const TAGS_TO_USE = USER_TAG ? [RUN_TAG, USER_TAG] : [RUN_TAG];

          const target = {}, targets = [];

          items.forEach((it, i) => {
            const name = `t${i}`;
            const tags = [];

            if ((PUSH === 'aws' || PUSH === 'both') && AWS) TAGS_TO_USE.forEach(t => tags.push(`${AWS}/${it.image_name}:${t}`));
            if ((PUSH === 'azure' || PUSH === 'both') && AZ) TAGS_TO_USE.forEach(t => tags.push(`${AZ}/${it.image_name}:${t}`));
            if (PUSH === 'none' && it.image_name)           TAGS_TO_USE.forEach(t => tags.push(`${it.image_name}:${t}`));

            // Context: if relative -> join with $GITHUB_WORKSPACE
            const ctxInput = it.context || '.';
            const ctxPath  = path.isAbsolute(ctxInput) ? ctxInput : path.join(ROOT, ctxInput);

            // Dockerfile: if relative -> join with $GITHUB_WORKSPACE (do NOT base on context)
            const dfInput  = it.build_file || 'Dockerfile';
            const dfPath   = path.isAbsolute(dfInput) ? dfInput : path.join(ROOT, dfInput);

            target[name] = {
              context:   toPosix(ctxPath),
              dockerfile: toPosix(dfPath),
              tags
            };

            if (it.cacheFrom?.length) target[name]['cache-from'] = it.cacheFrom;
            if (it.cacheTo?.length)   target[name]['cache-to']   = it.cacheTo;

            targets.push(name);
          });

          const bake = { group: { default: { targets } }, target };
          fs.writeFileSync('docker-bake.json', JSON.stringify(bake, null, 2));
          core.startGroup('docker-bake.json');
          core.info(fs.readFileSync('docker-bake.json','utf8'));
          core.endGroup();



    # Bake with live workspace (includes files generated earlier)
    - name: bake
      uses: docker/bake-action@v6
      with:
        source: .
        files: docker-bake.json
        push: ${{ inputs.push != 'none' }}
        # builder: remote-builder

